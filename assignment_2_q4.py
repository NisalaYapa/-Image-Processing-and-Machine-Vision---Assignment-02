# -*- coding: utf-8 -*-
"""Assignment_2_Q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pl349zUJ9HXKf1Pi5rPZmst2wcGYpWTW
"""

import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt

img1 = cv.imread('img1.ppm')
img5 = cv.imread('img5.ppm')


# Detect keypoints and compute descriptors
keypoints1, descriptors1 = cv.SIFT_create().detectAndCompute(img1, None)
keypoints5, descriptors5 = cv.SIFT_create().detectAndCompute(img5, None)

# Match descriptors between the two images
matches = cv.FlannBasedMatcher().knnMatch(descriptors1, descriptors5, k=2)

# select good matches
good_matches = []
for m, n in matches:
    if m.distance < 0.75 * n.distance:
        good_matches.append(m)

# Draw the matches
matched_image = cv.drawMatches(img1, keypoints1, img5, keypoints5, good_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# Display the matches and original images
fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))
ax1.imshow(img1, cmap='gray')
ax1.set_title('Image 1')
ax2.imshow(img5, cmap='gray')
ax2.set_title('Image 5')
plt.show()

fig2, ax = plt.subplots(figsize=(15, 15))
ax.imshow(matched_image)

image1_with_keypoints = cv.drawKeypoints(img1, keypoints1, None)
plt.imshow(image1_with_keypoints)

image5_with_keypoints = cv.drawKeypoints(img5, keypoints1, None)
plt.imshow(image5_with_keypoints)

def compute_homography_ransac(src_pts, dst_pts, num_iterations=1000, consensus_threshold=5.0):
    best_homography = None
    best_inliers = 0

    for _ in range(num_iterations):
        # Randomly sample 4 correspondences
        indices = np.random.choice(len(src_pts), 4, replace=False)
        src_sample = src_pts[indices]
        dst_sample = dst_pts[indices]

        # Compute the homography matrix for this sample
        homography, _ = cv.findHomography(src_sample, dst_sample)

        # Transform all source points using the current homography
        transformed_pts = cv.perspectiveTransform(src_pts.reshape(-1, 1, 2), homography)

        # Calculate distances between the transformed points and destination points
        errors = np.sqrt(np.sum((transformed_pts.squeeze() - dst_pts) ** 2, axis=1))

        # Count inliers (points within tolerance)
        inliers = np.sum(errors < consensus_threshold)

        # Update the best homography if this sample has more inliers
        if inliers > best_inliers:
            best_homography = homography
            best_inliers = inliers

    return best_homography

src_pts = np.float64([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
dst_pts = np.float64([keypoints5[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

ransac_homography = compute_homography_ransac(src_pts, dst_pts, num_iterations=500, consensus_threshold=40)
print("Estimated Homography Matrix:")
print(ransac_homography)

# Load the color versions of the images
img1_color = cv.imread('img1.ppm')
img5_color = cv.imread('img5.ppm')

# Apply the homography to img1 to align it with img5
stitched_image = cv.warpPerspective(img1_color, ransac_homography, (img5_color.shape[1], img5_color.shape[0]))

# Blend the two images
alpha = 0.3  #  blending factor
blended_image = cv.addWeighted(img5_color, 1 - alpha, stitched_image, alpha, 0)

# Display the stitched and blended image and the original images
fig1 , (ax1, ax2 ) = plt.subplots(1,2, figsize=(15,15))
ax1.imshow(img1_color)
ax1.set_title('Image 1')
ax2.imshow(img5_color)
ax2.set_title('Image 5')
plt.show()

fig2 , ax = plt.subplots()
ax.imshow(blended_image)

best_homography = np.array([[6.2544644e-01 , 5.7759174e-02 ,  2.2201217e+02],
   [2.2240536e-01 ,  1.1652147e+00 , -2.5605611e+01],
   [4.9212545e-04 , -3.6542424e-05 ,  1.0000000e+00]])

# Load the color versions of the images
img1_color = cv.imread('img1.ppm')
img5_color = cv.imread('img5.ppm')

# Apply the homography to img1 to align it with img5
stitched_image = cv.warpPerspective(img1_color, best_homography, (img5_color.shape[1], img5_color.shape[0]))

# Blend the two images
alpha = 0.3  # blending factor
blended_image = cv.addWeighted(img5_color, 1 - alpha, stitched_image, alpha, 0)

# Display the stitched and blended image and the original images
fig1 , (ax1, ax2 ) = plt.subplots(1,2, figsize=(15,15))
ax1.imshow(img1_color)
ax1.set_title('Image 1')
ax2.imshow(img5_color)
ax2.set_title('Image 5')
plt.show()

fig2 , ax = plt.subplots()
ax.imshow(blended_image)